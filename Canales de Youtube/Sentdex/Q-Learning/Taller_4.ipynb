{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Taller 4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPg/tgkRbcdNmKVTLBK/dv0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raaraya1/Personal-Proyects/blob/main/Canales%20de%20Youtube/Sentdex/Q-Learning/Taller_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tPrOBXzoxmK"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from matplotlib import style\n",
        "import time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "If0Dv948p-UR",
        "outputId": "aa6ff3e4-a2a2-4ced-c2a1-2e74bbe23e7a"
      },
      "source": [
        "SIZE = 10\n",
        "HM_EPISODES = 2000\n",
        "MOVE_PENALTY = 1\n",
        "ENEMY_PENALTY = 300\n",
        "FOOD_REWARD = 25\n",
        "\n",
        "epsilon = 0.9\n",
        "EPS_DECAY = 0.9998\n",
        "\n",
        "SHOW_EVERY = 200\n",
        "\n",
        "start_q_table = None\n",
        "LEARNING_RATE = 0.1\n",
        "DISCOUNT = 0.95\n",
        "\n",
        "PLAYER = 1\n",
        "FOOD_N = 2\n",
        "ENEMY_N = 3\n",
        "\n",
        "d = {1: (255, 175, 0), 2:(0, 255, 0), 3:(0, 0, 255)}\n",
        "\n",
        "class Blob:\n",
        "  def __init__(self):\n",
        "    self.x = np.random.randint(0, SIZE)\n",
        "    self.y = np.random.randint(0, SIZE)\n",
        "\n",
        "  def __str__(self):\n",
        "    return f'{self.x}, {self.y}'\n",
        "\n",
        "  def __sub__(self, other):\n",
        "    return (self.x-other.x, self.y-other.y)\n",
        "\n",
        "  def action(self, choise):\n",
        "    if choise == 0:\n",
        "      self.move(x=1, y=1)\n",
        "    elif choise == 1:\n",
        "      self.move(x=-1, y=-1)\n",
        "    elif choise == 2:\n",
        "      self.move(x=-1, y=1)\n",
        "    elif choise == 3:\n",
        "      self.move(x=1, y=-1)\n",
        "\n",
        "  def move(self, x=False, y=False):\n",
        "    if not x:\n",
        "      self.x += np.random.randint(-1, 2)\n",
        "    else:\n",
        "      self.x += x\n",
        "\n",
        "    if not y:\n",
        "      self.y += np.random.randint(-1, 2)\n",
        "    else:\n",
        "      self.y += yield\n",
        "\n",
        "    if self.x < 0:\n",
        "      self.x = 0\n",
        "    elif self.x > SIZE-1:\n",
        "      self.x = SIZE-1\n",
        "\n",
        "    if self.y < 0:\n",
        "      self.y = 0\n",
        "    elif self.y > SIZE-1:\n",
        "      self.y = SIZE-1\n",
        "\n",
        "  \n",
        "  if start_q_table is None:\n",
        "    q_table = {}\n",
        "    for x1 in range(-SIZE+1, SIZE):\n",
        "      for y1 in range(-SIZE+1, SIZE):\n",
        "        for x2 in range(-SIZE+1, SIZE):\n",
        "          for y2 in range(-SIZE+1, SIZE):\n",
        "            q_table[((x1, y1), (x2, y2))] = [np.random.uniform(-5, 0) for i in range(4)]\n",
        "  else:\n",
        "    with open(start_q_table, 'rb') as f:\n",
        "      q_table = pickle.load(f)\n",
        "\n",
        "  print(q_table)\n",
        "\n",
        "episode_rewards = []\n",
        "for episode in range(HM_EPISODES):\n",
        "  player = Blob()\n",
        "  food = Blob()\n",
        "  enemy = Blob()\n",
        "\n",
        "  if episode % SHOW_EVERY == 0:\n",
        "    print(f'on # {episode}, epsilon: {epsilon}')\n",
        "    print(f'{SHOW_EVERY} ep mena {np.mean(episode_rewards[-SHOW_EVERY:])}')\n",
        "    show = True\n",
        "  else:\n",
        "    show = False\n",
        "  \n",
        "  episode_reward = 0\n",
        "  for i in range(200):\n",
        "    obs = (player-food, player-enemy)\n",
        "    if np.random.random() > epsilon:\n",
        "      action = np.argmax(q_table[obs])\n",
        "    else:\n",
        "      action = np.random.randint(0, 4)\n",
        "\n",
        "    player.action(action)\n",
        "\n",
        "    if player.x == enemy.x and player.y == enemy.y:\n",
        "      reward = -ENEMY_PENALTY\n",
        "    elif player.x == food.x and player.y == food.y:\n",
        "      reward = FOOD_REWARD\n",
        "    else:\n",
        "      reward = -MOVE_PENALTY\n",
        "\n",
        "    new_obs = (player-food, player-enemy)\n",
        "    max_future_q = np.max(q_table[new_obs])\n",
        "    current_q = q_table[obs][action]\n",
        "\n",
        "    if reward == FOOD_REWARD:\n",
        "      new_q = FOOD_REWARD\n",
        "    elif reward == -ENEMY_PENALTY:\n",
        "      new_q = -ENEMY_PENALTY\n",
        "    else:\n",
        "      new_q = (1-LEARNING_RATE)*current_q + LEARNING_RATE*(reward + DISCOUNT*max_future_q)\n",
        "\n",
        "    q_table[obs][action] = new_q\n",
        "\n",
        "    if show:\n",
        "      env = np.zeros((SIZE, SIZE, 3), dtype=np.uint8)\n",
        "      env[food.y][food.x] = d[FOOD_N]\n",
        "      env[player.y][player.x] = d[PLAYER_N]\n",
        "      env[enemy.y][enemy.x] = d[ENEMY_N]\n",
        "\n",
        "      img = Image.fromarray(env, 'RGB')\n",
        "      img = img.resize((300, 300))\n",
        "      cv2.imshow('', np.array(img))\n",
        "      if reward == FOOD_REWARD or reward == -ENEMY_PENALTY:\n",
        "        if cv2.waitKey(500)&0xFF == ord('q'):\n",
        "          break\n",
        "      else:\n",
        "        if cv2.waitKey(1)&0xFF == ord('q'):\n",
        "          break\n",
        "\n",
        "    episode_reward += reward\n",
        "    if reward == FOOD_REWARD or reward == -ENEMY_PENALTY:\n",
        "      break\n",
        "\n",
        "  episode_rewards.append(episode_reward)\n",
        "  epsilon *= EPS_DECAY\n",
        "\n",
        "moving_avg = np.convolve(episode_rewards, np.ones((SHOW_EVERY, ))/SHOW_EVERY, mode='valid')\n",
        "plt.plot([i for i in range(len(moving_avg))], moving_avg) \n",
        "plt.ylable(f'reward {SHOW_EVERY} ma')\n",
        "plt.xlabel('episode #')\n",
        "plt.show()\n",
        "\n",
        "with open(f'qtable-{int(time.time())}.pickle', 'wb') as f:\n",
        "  pickle.dump(q_table, f)\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-46cda8164c7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mnew_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0menemy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mmax_future_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_obs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mcurrent_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'q_table' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k19uDFhupwL9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}