{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random Forest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/uKMqOYOAf0sej0ENWVC3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raaraya1/Personal-Proyects/blob/main/Canales%20de%20Youtube/Python%20Engineer/Random_Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMnEtbq3P5jY"
      },
      "source": [
        "# **Random Forest**\n",
        "\n",
        "Este algoritmo se contruye en base al algoritmo de **Decision Tree**. Asi, lo que se hace es:\n",
        "\n",
        "- Definir cantidad de estimadores (**Decision Tree**)\n",
        "- Cada estimador entrenarlo con una muestra del set de datos de entrenamiento, variando asi la cantidad de variables y la cantidad de datos con la cual se entrenan estos estimadores.\n",
        "- Luego, para generar la prediccion de algoritmo, lo que se hace es consultar a cada estimador su prediccion y \"**de manera democratica**\" se escoje la opción mas \"**votada**\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrtBtw4fRLax"
      },
      "source": [
        "## **Construyendo el algoritmo desde cero**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW1WjrPJPvlE"
      },
      "source": [
        "# Importar bibliotecas\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier as DecisionTree\n",
        "from collections import Counter"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaV2U4aPRqXr"
      },
      "source": [
        "# A partir de esta funcion es que genermos los sets de entrenamiento particulares para cada arbol\n",
        "def bootstrap_sample(X, y):\n",
        "  n_samples = X.shape[0]\n",
        "  idxs = np.random.choice(n_samples, size=n_samples, replace=True)\n",
        "  return X[idxs], y[idxs]\n",
        "\n",
        "# Con esta funcion buscamos extraer el valor (categoria) mas frecuente de una muestra\n",
        "def most_common_label(y):\n",
        "  counter = Counter(y)\n",
        "  most_common = counter.most_common(1)[0][0]\n",
        "  return most_common\n",
        "\n",
        "class RandomForest:\n",
        "  def __init__(self, n_trees=100, min_samples_split=2, max_depth=100, n_feats=None):\n",
        "    self.n_trees = n_trees\n",
        "    self.min_samples_split = min_samples_split\n",
        "    self.max_depth = max_depth\n",
        "    self.n_feats = n_feats\n",
        "    self.trees = []\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.trees = []\n",
        "    for _ in range(self.n_trees):\n",
        "      # Generamos un arbol\n",
        "      tree = DecisionTree(min_samples_split=self.min_samples_split,  \n",
        "                          max_depth = self.max_depth, max_features=self.n_feats)\n",
        "      \n",
        "      # Generamos un set de entrenamiento particular para el arbol, lo entrenamos y lo guardamos en nuestra lista de estimadores\n",
        "      X_sample, y_sample = bootstrap_sample(X, y)\n",
        "      tree.fit(X_sample, y_sample) \n",
        "      self.trees.append(tree)\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    # Generamos las predicciones \n",
        "    tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
        "\n",
        "    # Cambiamos el esquema en como son guardados los datos\n",
        "    tree_preds = np.swapaxes(tree_preds, 0, 1)\n",
        "\n",
        "    # Se asigna la prediccion como el valor mas frecuente\n",
        "    y_pred = [most_common_label(tree_pred) for tree_pred in tree_preds]\n",
        "    return np.array(y_pred)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNnYxE4JVfrH"
      },
      "source": [
        "## **Ahora probamos el algoritmo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoYI_IE0VeRv"
      },
      "source": [
        "# Importamos las bibliotecas\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6tmBGJtV1-o",
        "outputId": "be181b3b-f7fa-4ea0-93db-67798dcd74fb"
      },
      "source": [
        "# Funcion para medir el desempeño del algoritmo\n",
        "def accuracy(y_true, y_pred):\n",
        "  accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "  return accuracy\n",
        "\n",
        "# Importamos los datos\n",
        "data = datasets.load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Estos los separamos en los sets de entrenamiento y validacion\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "# Cargamos el algortimo y lo entrenamos\n",
        "clf = RandomForest(n_trees=3)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Generamos las predicciones y evaluamos su desempeño\n",
        "y_pred = clf.predict(X_test)\n",
        "acc = accuracy(y_test, y_pred)\n",
        "acc"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9035087719298246"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ahora probemos el algortimo que ofrece sklearn**"
      ],
      "metadata": {
        "id": "te0YjLK7lVip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar el clasificador\n",
        "from sklearn.ensemble import RandomForestClassifier as rf"
      ],
      "metadata": {
        "id": "LhFh-Vg2ld9L"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Llamamos al clasificador y lo entrenamos\n",
        "clf_sk = rf(n_estimators=3)\n",
        "clf_sk.fit(X_train, y_train)\n",
        "\n",
        "# Generamos las prediccion y evaluamos el acierto del algoritmo\n",
        "pred_sk = clf_sk.predict(X_test)\n",
        "acc_sk = accuracy(y_test, pred_sk)\n",
        "acc_sk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWZq2U3sly2n",
        "outputId": "a5494af0-a76a-463f-c878-52c725e51961"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9035087719298246"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}