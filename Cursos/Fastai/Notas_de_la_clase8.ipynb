{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Notas de la clase8.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ugyqqrLEuxge"
      ],
      "authorship_tag": "ABX9TyMu7PHrprm7cOkdfjRcw4Mb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raaraya1/Personal-Proyects/blob/main/Cursos/Fastai/Notas_de_la_clase8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ceRyBnrBnYi"
      },
      "source": [
        "# **Clase 8 - Deep Learning for Coders**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZkYFDJayL8y"
      },
      "source": [
        "# **Respuestas al cuestionario**\n",
        "\n",
        "**1. ¿Qué es el \"aprendizaje auto-supervisado\"?**\n",
        "\n",
        "El aprendizaje autosupervisado tiene por objetivo agrupar los elementos (generar categorias), pero sin llegar a conocer el nombre de la categoria por la cual se esta agrupando. En este sentido, este modelo se alimenta de informacion sin etiquetas (sin definir el target) y busca la mejor manera de ordenar los datos, de forma que, por ejemplo, en el predictor de palabras, al tener como entrada una cadena de texto, el modelo sea capaz de entregar la una palabra cercana a este grupo de palabras.\n",
        "\n",
        "**2. ¿Qué es un \"modelo de lenguaje\"?**\n",
        "\n",
        "Un modelo de lenguaje, es aquel modelo que fuen entrenado para predecir cual es la palabra siguiente en una cadena de texto.\n",
        "\n",
        "**3. ¿Por qué un modelo de lenguaje se considera auto-supervisado?**\n",
        "\n",
        "Se considera auto-supervisado, en el sentido de que es el propio modelo el que se encarga de etiquetar o agrupar los datos. (de darle cierta logica al ordenamiento)\n",
        "\n",
        "**4. ¿Para qué se utilizan habitualmente los modelos autocontrolados?**\n",
        "\n",
        "Estos suelen ser utilizados como modelos preentrenados y asi, realizar una transferencia de conocimiento.\n",
        "\n",
        "**5. ¿Por qué ajustamos los modelos de lenguaje?**\n",
        "\n",
        "Esto lo hacemos, ya que el modelo preentrenado maneja un cierto vocabulario de palabras pertenecientes a su training set. Sin embargo, si utilizamos este modelo preentrenado con un nuevo dataset, facilmente podrian aparecer nuevas palabras. Asi, este no sabria como tratar estos datos nuevos.\n",
        "\n",
        "**6. ¿Cuáles son los tres pasos para crear un clasificador de texto de última generación?**\n",
        "\n",
        "1. Tokenize el nuevo set de datos.\n",
        "2. Realizar un proceso de `fit_one_cycle` al modelo de lenguaje con el nuevo set de datos (ya numerizados), luego de este se obtiene el Encoder.\n",
        "3. Armar el modelo del clasificador (misma estructura que el modelo del lenguaje, salvo la capa de salida), 'pegarle' los parametros guardados en el Enconder. Por ultimo, ir actualizando de a poco las ultimas capas del modelo mediante los metodos `fit_one_cycle` y `freeze_to` y al final descongelar todo, para continuar entrenando. \n",
        "\n",
        "**7. ¿Cómo nos ayudan las 50.000 reseñas de películas sin etiquetas a crear un mejor clasificador de texto para el conjunto de datos de IMDb?**\n",
        "\n",
        "Como el modelo del lenguaje no requiere pasarle datos etiquetados, estos 50.000 datos extras ayudaran a que el proceso de ajuste cuente con mayor informacion de como realizar las agrupaciones. Luego, este modelo de lenguaje contara con nueva informacion de palabras para el modelo de clasificacion. (en resumidas palabras, tendra un mejor ajuste de los grupos y contara con nuevas palabras para interpretar) \n",
        "\n",
        "**8. ¿Cuáles son los tres pasos para preparar sus datos para un modelo de lenguaje?**\n",
        "\n",
        "1. Definir y aplicar un metodo de tokenization. (en la clase se dan a conocer 3)\n",
        "2. Numeralizar los tokens.\n",
        "3. Generar una cadena de texto gigante y segmentarla en trozos (mini-batches). Esto se hace con el modulo de `LMDataLoader`.\n",
        "\n",
        "**9. ¿Qué es la \"tokenización\"? ¿Por qué lo necesitamos?**\n",
        "\n",
        "Con esta podemos identificar, dentro de una cadena de texto, los caracteres o palabras contenidos. Esto es necesario, en el sentido que el modelo no entiende palabras, solo entiende numeros, por lo que, al aplicar estas reglas sobre una cadena de texto, luego se podra numerar las palabras y estas numeraciones luego hacerlas pasar al modelo.\n",
        "\n",
        "**10. Nombra tres enfoques diferentes para la tokenización.**\n",
        "\n",
        " - Word-based\n",
        " - Subword-based\n",
        " - Character-based\n",
        "\n",
        "**11. ¿Qué es \"xxbos\"?**\n",
        "\n",
        "Este es un indicador que utiliza Fastai para señalar el inicio de una oracion. (me parece que 'bos' es por 'begining of sentence')\n",
        "\n",
        "**12. Enumere cuatro reglas que fastai aplica al texto durante la tokenización.**\n",
        "\n",
        "```\n",
        "xxbos: begining of stream\n",
        "xxup : upper 'word'\n",
        "xxmaj: the next word begin with capital letter\n",
        "xxunk: unknown word\n",
        "©    : special character\n",
        "xxrep: repited 'times', 'letter'\n",
        "```\n",
        "\n",
        "**13. ¿Por qué los caracteres repetidos se reemplazan por una ficha que muestra el número de repeticiones y el carácter que se repite?**\n",
        "\n",
        "De esta manera, la matriz de embedding puede codificar informacion mas general sobre conceptos que andar haciendo un token por cada caracter repetido.\n",
        "\n",
        "**14. ¿Qué es la \"numerización\"?**\n",
        "\n",
        "Este es el proceso de transformar los tokens a numero.\n",
        "\n",
        "1. Primero hacemos una lista de todas los niveles (palabras) que se pueden encontrar (diccionario)\n",
        "2. Replazar cada uno de estos niveles con el indice del diccionario.\n",
        "\n",
        "**15. ¿Por qué puede haber palabras que se reemplacen con la ficha de \"palabra desconocida\"?**\n",
        "\n",
        "La ficha de palabra desconocida es `xxunk` y esta puede surgir de manera natural, es decir que, al buscar en el diccionario, no se encuentra la palabra, o puede surgir de manera intencionada como el metodo que utiliza fastai para generar los batch en el modelo de clasificacion (como el tamaño de los textos difieren, lo que hace fastai es rellenar con estos caracteres)\n",
        "\n",
        "**16. Con un batch size de 64, la primera fila del tensor que representa el primer batch contiene los primeros 64 tokens para el conjunto de datos. ¿Qué contiene la segunda fila de ese tensor? ¿Qué contiene la primera fila del segundo batch?.**\n",
        "\n",
        "Ojo, que en la clase aparece que cada batch contienen, por defecto, 72 tokens y no 64.\n",
        "\n",
        "Luego, respondiendo a la primera pregunta (y suponiendo 64 tokens en lugar de 72 por batch), en la segunda fila del tensor se encuentra el segundo token del batch.\n",
        "\n",
        "Luego, la primera fila del segundo batch, tambien contiene un token (y creo que este seria 'xxbos')\n",
        "\n",
        "Para dejarlo mas claro, aqui dejo el mismo ejercicio aplicado a otro ejemplo.\n",
        "\n",
        "```python\n",
        "# generamos unos textos de prueba\n",
        "texto1 = [\"Este texto lo voy a ocupar de prueba y la idea es poder ir registrando los batch y su contenido, para asi corroborar que no estamos haciendo tonteras. \"]\n",
        "texto2 = [\"Espero, no confundir con esto, pero tambien en esta parte lo que se hace es agrupar los textos y aplicarles el tokenizer (antes de separar en batches). \"]\n",
        "textos = texto1 + texto2\n",
        "\n",
        "# luego los pasamos a tokens\n",
        "spacy = WordTokenizer()\n",
        "tkn = Tokenizer(spacy)\n",
        "txts = [tkn(i) for i in textos]\n",
        "\n",
        "# luego generamos el diccionario \n",
        "## nota: si quiero que aparezcan todas las palabras debo fijar min_freq=1\n",
        "num = Numericalize(min_freq=1)\n",
        "num.setup(txts)\n",
        "\n",
        "# luego pasamos los tokens a numero\n",
        "numeros = [num(i) for i in txts]\n",
        "\n",
        "# luego cargamos un dataloader y vamos respondiendo a las preguntas\n",
        "dl = LMDataLoader(numeros, bs=3, seq_len=22)\n",
        "\n",
        "# antes, miremos que lo hicimos bien (notar que el target contiene el token siguiente)\n",
        "x,y = first(dl)\n",
        "## batch1\n",
        "batch1 = [num.vocab[i] for i in x[0]]\n",
        "print(batch1[-3:])\n",
        ">>> ['batch', 'y', 'su']\n",
        "## target1\n",
        "target1 = [num.vocab[i] for i in y[0]]\n",
        "print(target1[-3:])\n",
        ">>> ['y', 'su', 'contenido']\n",
        "\n",
        "\n",
        "# Ahora si, respondemos a las preguntas\n",
        "## 1) que contiene la segunda fila del primer batch?\n",
        "res1 = x[0][1]\n",
        "print(f'token a numero: {res1}  token a texto: {num.vocab[res1]}')\n",
        ">>> token a numero: 8  token a texto: xxmaj\n",
        "\n",
        "\n",
        "## 2) que contiene la primera fila del segundo batch?\n",
        "res2 = x[1][0]\n",
        "print(f'token a numero: {res2}  token a texto: {num.vocab[res2]}')\n",
        ">>> token a numero: 32  token a texto: contenido\n",
        "```\n",
        "\n",
        "**17. ¿Por qué necesitamos relleno para la clasificación de texto? ¿Por qué no lo necesitamos para modelar el lenguaje?**\n",
        "\n",
        "Lo que sucede es que, cuando generamos los batches para el modelo del lenguaje, lo que se hace es agarrar todos los textos, poner todos los tokens en secuencia y luego cortar en trozos (segun alguna cantidad de tokens). Asi es como generamos los batches del modelo de lenguaje y a gracia es que todos estos tienen la misma cantidad de tokens (lo que es necesario, porque la entrada del modelo debe tener una cantidad fija de datos de entrada)\n",
        "\n",
        "Por el contrario, para el modelo de clasificacion los batches corresponden a los textos de manera individual con lo cual cada uno varia en la cantidad de tokens que contiene. Asi, una forma sencilla de arreglar esto (y tener una cantidad fija de datos de entrada al modelo) es rellerar los batches con menos cantidad de tokens para asi emparejarlos con el resto.\n",
        "\n",
        "**18. ¿Qué contiene un embedding matrix para NLP? Cual es su forma?**\n",
        "\n",
        "Un embedding matrix contiene para cada una de sus filas, cada item del diccionario de palabras. Estas se utilizan al inicio del modelo de redes neuronales, las cuales toman como input los indices del vocabulario (similar a tomar vectores de one-hot encodding, pero mas rapido)\n",
        "\n",
        "**19. ¿Qué es \"perplexity\"?**\n",
        "\n",
        "Es una metrica que generalmente se utiliza para modelos del lenguaje y esta corresponde a la exponencial de la funcion de perdida (cross entropy)\n",
        "\n",
        "**20. ¿Por qué tenemos que pasar el vocabulario del modelo de lenguaje al bloque de datos del clasificador?**\n",
        "\n",
        "Porque, el modelo de AWD_LSTM, viene con un embedding matrix dedicado al conjunto de datos de wikipedia, por lo cual, si queremos hacer que calzen los parametros entrenados del encoder (obtenido del modelo de lenguaje con las reseñas de IMDb), necesitamos ajustar nuevamente la arquitectura del modelo AWD_LSTM agreagrando el diccionario de palabras (vocabulario).\n",
        "\n",
        "**21. ¿Qué es \"gradual unfreezing\"?**\n",
        "\n",
        "En la ultima etapa de esta clase utilizamos este concepto al ir actualizando los parametros de las ultimas capas de manera gradual, es decir, primero congelamos todos los parametros salvo la ultima capa (esta puede variar sus parametros), luego congelamos todos los parametros salvo las ultimas dos capas y asi sucesivamente.\n",
        "\n",
        "**22. ¿Por qué es probable que la generación de texto esté siempre por delante de la identificación automática de textos generados por máquina?**\n",
        "\n",
        "Al menos, en el texto de la clase, se da a entender que el algoritmo discriminador (verificar si el texto es real o no), requiere estar constantemente actualizandose con informacion fidedigna e informacion generada. LO MALO, es que los algoritmos generadores pueden incluir dentro de su estructura una red discriminadora y asi, esta nueva estructura (que incluye una red generadora y una discriminadora) puede estar constantemente actualizandose para vulnerar la deteccion de otras redes discriminadoras (si no me equivoco este tipo de estructuras de redes neuronales se llaman 'Redes Neuronales Generativas Adversarias')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY--zo5gsnOo"
      },
      "source": [
        "# **NLP Deep Dive: RNNs**\n",
        "\n",
        "Lo que vamos a hacer es utilizar una red neuronal, pero en este caso no vamos a con un metodo de aprendizaje profundo, sino que en esta ocacion vamos a utilizar un aprendizaje auto-supervisado (En este caso no necesitamos etiquetar los datos).\n",
        "\n",
        "Asi, en esta clase vamos a utilizar un modelo preentrenado de lenguaje (predice la siguiente palabra) como base para un modelo de clasificacion de peliculas.\n",
        "\n",
        "Lo que vamos a hacer.\n",
        "\n",
        "- Primero, vamos a rescatar el modelo de lenguaje (preentrenado)que se contruyo en base a un dataset de wikipedia\n",
        "- Luego, vamos a rescatar las reseñas de IMDb (25.000 train, 25.000 validation y 50.000 sin cclasificar) y vamos a hacer un fine-tune con estos datos\n",
        "- Este metodo es llamado 'Universal Language Model Fine-tuning (ULMFit)' y lo que nos va a generar es un modelo con mayor acierto en predecir la siguiente palabra en una reseña de pelicula.\n",
        "- Ya, a partir de aqui, generamos el clasificador (tambien con un fine-tuning, pero al modelo de lenguaje modificado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugyqqrLEuxge"
      },
      "source": [
        "## **Text Preprocessing**\n",
        "\n",
        "1. Hacer una lista de todas las palabras (vocabulario)\n",
        "2. Reemplazar cada palabra, con le indice guardado en el diccionario.\n",
        "3. Crear un embedding matrix que tenga una fila por cada elemento del diccionario.\n",
        "4. Usar este embedding matrix como la primera capa del modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dghC7KThx16Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90f12336-a9b4-43da-d4dc-9bfefdd578ce"
      },
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "from fastbook import *\n",
        "from IPython.display import display,HTML\n",
        "from fastai.text.all import *\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 720 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 186 kB 44.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 34.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 300 kB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02IGTzVIu2pl"
      },
      "source": [
        "### **Tokenization**\n",
        "\n",
        "Tokenization mas comunes.\n",
        " - word-based: separar una oracion por espacios.\n",
        " - subword based: separa las oraciones en subgrupos de letras (las que mas se repitan)\n",
        " - character-based: separar por letras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVPH4XlhyDHZ"
      },
      "source": [
        "### **Word Tokenization with fastai**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "DyQ39dSSx88R",
        "outputId": "c935ffc0-f9f5-4d14-c446-323ab32133da"
      },
      "source": [
        "# Primero descarguemos los datos de las reseñas de IMDb\n",
        "from fastai.text.all import *\n",
        "path = untar_data(URLs.IMDB)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='144441344' class='' max='144440600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [144441344/144440600 00:03<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuZlC3qwzeRn",
        "outputId": "c0af17b5-972f-41b2-da41-052b70a7e704"
      },
      "source": [
        "# Ahora quiero corroborar la cantidad de datos\n",
        "## train\n",
        "print(len((path/'train/pos').ls()))\n",
        "print(len((path/'train/neg').ls()))\n",
        "\n",
        "## no-supervisado (sin etiquetar)\n",
        "print(len((path/'unsup').ls()))\n",
        "\n",
        "## test (validacion)\n",
        "print(len((path/'test/pos').ls()))\n",
        "print(len((path/'test/neg').ls()))\n",
        "\n",
        "# Todos estos son los archivos de texto (reseñas) que tengo que juntar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12500\n",
            "12500\n",
            "50000\n",
            "12500\n",
            "12500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52wnexzvvoAp"
      },
      "source": [
        "# Esto lo podemos hacer rapidamente con el metodo get_text_files, el cual buscar\n",
        "# todos los archivos de texto contedinos del las carpetas seleccionadas\n",
        "files = get_text_files(path, folders = ['train', 'test', 'unsup'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3tbvRdszrdo",
        "outputId": "d858084e-409b-4731-93c5-1e7cc998d90d"
      },
      "source": [
        "files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#100000) [Path('/root/.fastai/data/imdb/test/pos/2456_10.txt'),Path('/root/.fastai/data/imdb/test/pos/9325_9.txt'),Path('/root/.fastai/data/imdb/test/pos/1384_9.txt'),Path('/root/.fastai/data/imdb/test/pos/8457_9.txt'),Path('/root/.fastai/data/imdb/test/pos/9908_7.txt'),Path('/root/.fastai/data/imdb/test/pos/9165_8.txt'),Path('/root/.fastai/data/imdb/test/pos/4981_8.txt'),Path('/root/.fastai/data/imdb/test/pos/6976_10.txt'),Path('/root/.fastai/data/imdb/test/pos/11426_7.txt'),Path('/root/.fastai/data/imdb/test/pos/3618_10.txt')...]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "n6ZKymlNvrxl",
        "outputId": "7cd6253f-c536-4956-80e4-941028854a8c"
      },
      "source": [
        "# Aqui, por ejemplo, podemos ver la primera reseña \n",
        "txt = files[0].open().read()\n",
        "txt[:75]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Estevez, Martin Sheen and Kathy Bates are superb in this portrayal of a Vie'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyUQhustv14k",
        "outputId": "19bd4bbc-20bd-4999-9682-e0278f6c940b"
      },
      "source": [
        "# Lo que vamos a hacer aqui es segmentar las oraciones por espacios (con algunas reglas extras)\n",
        "spacy = WordTokenizer() # separador por espacios\n",
        "\n",
        "\n",
        "toks = first(spacy([txt]))\n",
        "print(coll_repr(toks, 30))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(#165) ['Estevez',',','Martin','Sheen','and','Kathy','Bates','are','superb','in','this','portrayal','of','a','Vietnam','vet','home','from','the','war','but','still','haunted','by','it','.','Bates','plays','a','clueless'...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "hNL_6-iCN2AP",
        "outputId": "ee3070a3-89e7-4bfd-9e9e-ba4d0eb18bbd"
      },
      "source": [
        "# Probemos con otro ejemplo\n",
        "test = '''Probemos con esta oracion de prueba, PD: es interesante ver como trabaja\n",
        "para el español'''\n",
        "print(test)\n",
        "\n",
        "a = first(spacy([test]))\n",
        "coll_repr(a, 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probemos con esta oracion de prueba, PD: es interesante ver como trabaja\n",
            "para el español\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"(#18) ['Probemos','con','esta','oracion','de','prueba',',','PD',':','es','interesante','ver','como','trabaja','\\\\n','para','el','español']\""
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzMvxg6Kv7u2",
        "outputId": "25eb3828-f03f-4559-c652-01643b38c057"
      },
      "source": [
        "# Bien, ahora vamos a aplicar un metodo que proportciona fastai para identificar\n",
        "# las operaciones que realiza sobre las oraciones\n",
        "tkn = Tokenizer(spacy)\n",
        "print(coll_repr(tkn(txt), 31))\n",
        "print(coll_repr(tkn(test), 31))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(#184) ['xxbos','xxmaj','estevez',',','xxmaj','martin','xxmaj','sheen','and','xxmaj','kathy','xxmaj','bates','are','superb','in','this','portrayal','of','a','xxmaj','vietnam','vet','home','from','the','war','but','still','haunted','by'...]\n",
            "(#21) ['xxbos','xxmaj','probemos','con','esta','oracion','de','prueba',',','xxup','pd',':','es','interesante','ver','como','trabaja','\\n','para','el','español']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BD-RoYETNzX",
        "outputId": "8f61e3ba-f15f-4ad9-f090-d807485e91c7"
      },
      "source": [
        "prueba = L(test[:20]).map(tkn)\n",
        "prueba"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#1) [['xxbos', 'xxmaj', 'probemos', 'con', 'esta', 'or']]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyqkkGgXwNzC",
        "outputId": "64ae3058-713b-4fc3-bb86-4da2d5fe8851"
      },
      "source": [
        "# estas son las reglas adicionales que se aplican\n",
        "defaults.text_proc_rules"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<function fastai.text.core.fix_html>,\n",
              " <function fastai.text.core.replace_rep>,\n",
              " <function fastai.text.core.replace_wrep>,\n",
              " <function fastai.text.core.spec_add_spaces>,\n",
              " <function fastai.text.core.rm_useless_spaces>,\n",
              " <function fastai.text.core.replace_all_caps>,\n",
              " <function fastai.text.core.replace_maj>,\n",
              " <function fastai.text.core.lowercase>]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otshpyLBQghJ"
      },
      "source": [
        "```\n",
        "Algunas de las notaciones:\n",
        "xxbos: begining of sentence\n",
        "xxbaj: \n",
        "xxup : upper 'word'\n",
        "©    : special character\n",
        "xxrep: repited 'times', 'letter'\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xf5xmM6wwNo7",
        "outputId": "31c564bb-3d70-451f-8a61-95200d36c51f"
      },
      "source": [
        "coll_repr(tkn('&copy;   Fast.ai www.fast.ai/INDEX'), 31)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"(#11) ['xxbos','©','xxmaj','fast.ai','xxrep','3','w','.fast.ai','/','xxup','index']\""
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaUDb8L4yL71"
      },
      "source": [
        "### **Subword Tokenization**\n",
        "\n",
        "1. Analizar el cuerpo del texto y hallar los gropos mas fercuentes de letras (estos luego pasan a funcionar como el diccionario)\n",
        "\n",
        "2. Aplicar una separacion del texto, mirando el vocabulario creado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNmOiu7FwNej"
      },
      "source": [
        "# Por ejemplo, vamos a utilizar este texto\n",
        "txts = L(o.open().read() for o in files[:2000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDOtOYLiwNUP"
      },
      "source": [
        "# Lo que vamos a hacer aqui es denifir el tamaño del diccionario con el cual\n",
        "# queremos trabajar (vocab_sz), para luego generar las segmentaciones\n",
        "def subword(sz):\n",
        "    sp = SubwordTokenizer(vocab_sz=sz)\n",
        "    sp.setup(txts)\n",
        "    return ' '.join(first(sp([txt]))[:40])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "13O1aE7fwNI6",
        "outputId": "51d1ef26-714c-43ce-ce26-b1e5d482ee22"
      },
      "source": [
        "# Por ejemplo, si quisieramos trabajar con un diccionario de tamaño 1000\n",
        "subword(1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"▁Qu it e ▁simply , ▁one ▁of ▁the ▁sh ar p est ▁screen play s ▁ever ▁written ▁and ▁ lu ck i ly ▁it ▁has ▁performance s ▁to ▁m atch . ▁This ▁movie , ▁and ▁if ▁you ▁have n '\""
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7tyWs2tjwM-y",
        "outputId": "cd230b57-c828-4546-c085-91de5a85a1ce"
      },
      "source": [
        "# O uno de tamaño 200 (aqui se nota que le cuesta mas hacer grupos de letras mas grandes)\n",
        "subword(200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'▁ Q u it e ▁s i m p ly , ▁on e ▁of ▁the ▁s h ar p es t ▁s c re en p la y s ▁ e ver ▁w ri t t en ▁and ▁ l'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "-OkQVG-CwMyB",
        "outputId": "770ea3d6-2772-4250-8871-0f6053838eea"
      },
      "source": [
        "# Por el contrario, si aumentamos el tamaño del diccionario, se podran generar\n",
        "# grupos de letras mas grandes (alcanzando a cubrir palabras)\n",
        "subword(10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"▁Qui te ▁simply , ▁one ▁of ▁the ▁sharp est ▁screenplay s ▁ever ▁written ▁and ▁luck ily ▁it ▁has ▁performances ▁to ▁match . ▁This ▁movie , ▁and ▁if ▁you ▁haven ' t ▁seen ▁it ▁then ▁you ▁really ▁should ▁rush ▁out ▁to\""
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th2GF17nyRqD"
      },
      "source": [
        "### **Numericalization with fastai**\n",
        "\n",
        "1. Hacer una lista con todas las palabras enumeradas (diccionario)\n",
        "2. Reemplazar cada palabra con su numeracion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiS4sdUrwMoP",
        "outputId": "65e3c979-0a2f-4c63-ca3b-5b16e4260295"
      },
      "source": [
        "# Veamos el siguiente ejemplo\n",
        "toks = tkn(txt)\n",
        "print(coll_repr(tkn(txt), 31))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(#184) ['xxbos','xxmaj','estevez',',','xxmaj','martin','xxmaj','sheen','and','xxmaj','kathy','xxmaj','bates','are','superb','in','this','portrayal','of','a','xxmaj','vietnam','vet','home','from','the','war','but','still','haunted','by'...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAzWTgUAwMek",
        "outputId": "aaf6a9fc-b394-4c92-f6fc-8843ce7b98a5"
      },
      "source": [
        "# Con la funcion map, puedo aplicar una funcion mirando los elementos\n",
        "toks200 = txts[:200].map(tkn)\n",
        "toks200[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#184) ['xxbos','xxmaj','estevez',',','xxmaj','martin','xxmaj','sheen','and','xxmaj'...]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "_xtQoUpawMS1",
        "outputId": "f86e184e-0adb-4ad6-87d0-0166ad93d642"
      },
      "source": [
        "# Creamos el objeto Numericalize (es de Fastai)\n",
        "# Luego, a este objeto le cargamos el texto y listo\n",
        "## Ojo, que el objeto Numericalize tiene por defecto un diccionario maximo de 60.000\n",
        "## En este caso, si dejamos este parametro tal como esta y resulta que en realidad\n",
        "## existen mas de 60.000 palabras en el diccionario, todas las extras se cambiaran por\n",
        "## 'xxunk', ademas existe otro parametro min_frec=3, que tambien reemplaza las palabras\n",
        "## por 'xxunk', pero las que aparezcan menos de 3 veces en el texto\n",
        "num = Numericalize()\n",
        "num.setup(toks200)\n",
        "coll_repr(num.vocab,20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"(#1992) ['xxunk','xxpad','xxbos','xxeos','xxfld','xxrep','xxwrep','xxup','xxmaj','the',',','.','and','a','of','to','is','it','in','i'...]\""
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCLp6Us9wMJO",
        "outputId": "ecd20631-2259-45e1-b532-5681b4fb1ae3"
      },
      "source": [
        "# Aqui, por ejemplo podemos ver como dejo la anterior frase commo una secuencia \n",
        "# de numeros\n",
        "nums = num(toks)[:20]; nums"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorText([   2,    8,  827,   10,    8,  718,    8,  719,   12,    8, 1487,    8,  965,   42,  630,   18,   20,  828,   14,   13])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7oF2m0ZVwL-y",
        "outputId": "7d0811af-2d54-46fe-936e-ea02ca944467"
      },
      "source": [
        "# Ahora, si queremos volver a armar la frase\n",
        "' '.join(num.vocab[o] for o in nums)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'xxbos xxmaj quite simply , one of the xxunk xxunk ever written and xxunk it has performances to match .'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGkLQWc_yW7Z"
      },
      "source": [
        "### **Putting Our Texts into Batches for a Language Model**\n",
        "\n",
        "La principal dificultad que se presenta ahora es que, no todos los textos contienen la misma cantidad de palabras y necesitamos una cantidad estructurada de informacion que entre al modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "SU2fsoaBwL0k",
        "outputId": "0be708c0-c973-42ec-ca3e-f9a036ef8220"
      },
      "source": [
        "# Por ejemplo, en este texto, podriamos tratar de generar 6 muestras (batches)\n",
        "# con 15 palabras cada una\n",
        "stream = \"In this chapter, we will go back over the example of classifying movie reviews we studied in chapter 1 and dig deeper under the surface. First we will look at the processing steps necessary to convert text into numbers and how to customize it. By doing this, we'll have another example of the PreProcessor used in the data block API.\\nThen we will study how we build a language model and train it for a while.\"\n",
        "tokens = tkn(stream)\n",
        "bs,seq_len = 6,15\n",
        "d_tokens = np.array([tokens[i*seq_len:(i+1)*seq_len] for i in range(bs)])\n",
        "df = pd.DataFrame(d_tokens)\n",
        "display(HTML(df.to_html(index=False,header=None)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>in</td>\n",
              "      <td>this</td>\n",
              "      <td>chapter</td>\n",
              "      <td>,</td>\n",
              "      <td>we</td>\n",
              "      <td>will</td>\n",
              "      <td>go</td>\n",
              "      <td>back</td>\n",
              "      <td>over</td>\n",
              "      <td>the</td>\n",
              "      <td>example</td>\n",
              "      <td>of</td>\n",
              "      <td>classifying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>movie</td>\n",
              "      <td>reviews</td>\n",
              "      <td>we</td>\n",
              "      <td>studied</td>\n",
              "      <td>in</td>\n",
              "      <td>chapter</td>\n",
              "      <td>1</td>\n",
              "      <td>and</td>\n",
              "      <td>dig</td>\n",
              "      <td>deeper</td>\n",
              "      <td>under</td>\n",
              "      <td>the</td>\n",
              "      <td>surface</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>first</td>\n",
              "      <td>we</td>\n",
              "      <td>will</td>\n",
              "      <td>look</td>\n",
              "      <td>at</td>\n",
              "      <td>the</td>\n",
              "      <td>processing</td>\n",
              "      <td>steps</td>\n",
              "      <td>necessary</td>\n",
              "      <td>to</td>\n",
              "      <td>convert</td>\n",
              "      <td>text</td>\n",
              "      <td>into</td>\n",
              "      <td>numbers</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>how</td>\n",
              "      <td>to</td>\n",
              "      <td>customize</td>\n",
              "      <td>it</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>by</td>\n",
              "      <td>doing</td>\n",
              "      <td>this</td>\n",
              "      <td>,</td>\n",
              "      <td>we</td>\n",
              "      <td>'ll</td>\n",
              "      <td>have</td>\n",
              "      <td>another</td>\n",
              "      <td>example</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>of</td>\n",
              "      <td>the</td>\n",
              "      <td>preprocessor</td>\n",
              "      <td>used</td>\n",
              "      <td>in</td>\n",
              "      <td>the</td>\n",
              "      <td>data</td>\n",
              "      <td>block</td>\n",
              "      <td>xxup</td>\n",
              "      <td>api</td>\n",
              "      <td>.</td>\n",
              "      <td>\\n</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>then</td>\n",
              "      <td>we</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>will</td>\n",
              "      <td>study</td>\n",
              "      <td>how</td>\n",
              "      <td>we</td>\n",
              "      <td>build</td>\n",
              "      <td>a</td>\n",
              "      <td>language</td>\n",
              "      <td>model</td>\n",
              "      <td>and</td>\n",
              "      <td>train</td>\n",
              "      <td>it</td>\n",
              "      <td>for</td>\n",
              "      <td>a</td>\n",
              "      <td>while</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "R8nFVJGNwLpX",
        "outputId": "96285192-7037-4b1b-d43d-d0fc3408776d"
      },
      "source": [
        "# Lo que vamos a hacer ahora es dividir lo que tenemos arriba en 3 grupos de 5 palabras\n",
        "## GRUPO 1 (Primeras 5 columnas)\n",
        "bs,seq_len = 6,5\n",
        "d_tokens = np.array([tokens[i*15:i*15+seq_len] for i in range(bs)])\n",
        "df = pd.DataFrame(d_tokens)\n",
        "display(HTML(df.to_html(index=False,header=None)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>in</td>\n",
              "      <td>this</td>\n",
              "      <td>chapter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>movie</td>\n",
              "      <td>reviews</td>\n",
              "      <td>we</td>\n",
              "      <td>studied</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>first</td>\n",
              "      <td>we</td>\n",
              "      <td>will</td>\n",
              "      <td>look</td>\n",
              "      <td>at</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>how</td>\n",
              "      <td>to</td>\n",
              "      <td>customize</td>\n",
              "      <td>it</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>of</td>\n",
              "      <td>the</td>\n",
              "      <td>preprocessor</td>\n",
              "      <td>used</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>will</td>\n",
              "      <td>study</td>\n",
              "      <td>how</td>\n",
              "      <td>we</td>\n",
              "      <td>build</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "7BiJOXqXwLdb",
        "outputId": "9872a7cd-5cc1-4d5f-96a4-72ba12d77416"
      },
      "source": [
        "## GRUPO 2 (Desde columna 5 a columna 9)\n",
        "bs,seq_len = 6,5\n",
        "d_tokens = np.array([tokens[i*15+seq_len:i*15+2*seq_len] for i in range(bs)])\n",
        "df = pd.DataFrame(d_tokens)\n",
        "display(HTML(df.to_html(index=False,header=None)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>,</td>\n",
              "      <td>we</td>\n",
              "      <td>will</td>\n",
              "      <td>go</td>\n",
              "      <td>back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>chapter</td>\n",
              "      <td>1</td>\n",
              "      <td>and</td>\n",
              "      <td>dig</td>\n",
              "      <td>deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>the</td>\n",
              "      <td>processing</td>\n",
              "      <td>steps</td>\n",
              "      <td>necessary</td>\n",
              "      <td>to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxmaj</td>\n",
              "      <td>by</td>\n",
              "      <td>doing</td>\n",
              "      <td>this</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>the</td>\n",
              "      <td>data</td>\n",
              "      <td>block</td>\n",
              "      <td>xxup</td>\n",
              "      <td>api</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>a</td>\n",
              "      <td>language</td>\n",
              "      <td>model</td>\n",
              "      <td>and</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "2APV_C6nwLTY",
        "outputId": "7aa58dc9-d6e0-4503-c602-e778e8e10552"
      },
      "source": [
        "## GRUPO 3 (Desde columna 10 a 14)\n",
        "bs,seq_len = 6,5\n",
        "d_tokens = np.array([tokens[i*15+10:i*15+15] for i in range(bs)])\n",
        "df = pd.DataFrame(d_tokens)\n",
        "display(HTML(df.to_html(index=False,header=None)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>over</td>\n",
              "      <td>the</td>\n",
              "      <td>example</td>\n",
              "      <td>of</td>\n",
              "      <td>classifying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>under</td>\n",
              "      <td>the</td>\n",
              "      <td>surface</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>convert</td>\n",
              "      <td>text</td>\n",
              "      <td>into</td>\n",
              "      <td>numbers</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>we</td>\n",
              "      <td>'ll</td>\n",
              "      <td>have</td>\n",
              "      <td>another</td>\n",
              "      <td>example</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>.</td>\n",
              "      <td>\\n</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>then</td>\n",
              "      <td>we</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>it</td>\n",
              "      <td>for</td>\n",
              "      <td>a</td>\n",
              "      <td>while</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ1gLVTQwLIr"
      },
      "source": [
        "# Con este paso, vamos a numeralizar todos los textos\n",
        "nums200 = toks200.map(num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebNRJCGGwK--"
      },
      "source": [
        "# Luego lo pasamos a un datalooader\n",
        "# Este dataloader primero desordena los documentos (no las oraciones)y luego las\n",
        "# segmenta segun el tamaño del batch-size que especifiquemos\n",
        "dl = LMDataLoader(nums200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_fV0lRqwK1c",
        "outputId": "34d8e14e-9ea1-4a10-d4f1-022f053815f4"
      },
      "source": [
        "# Aqui por ejemplo podemos ver que se esta utilzando por defecto un BS de 64\n",
        "# y 72 palabras para cada muestra\n",
        "x,y = first(dl)\n",
        "x.shape,y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 72]), torch.Size([64, 72]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e47ayG64EiH",
        "outputId": "b65050de-5df6-4f89-cf61-a1fe758e8a19"
      },
      "source": [
        "# Por ejemplo, aqui podemos ver el primer input\n",
        "x[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LMTensorText([   2,    8,  827,   10,    8,  718,    8,  719,   12,    8, 1487,    8,  965,   42,  630,   18,   20,  828,   14,   13,    8,  966, 1488,  259,   51,    9,  144,   31,  103, 1489,   43,   17,\n",
              "          11,    8,  965,  223,   13,    0,  294,   49,   64,  501,    9,  129,   15,   44,   13,   22,  129,   11,   22,    8,  719,   16, 1175,   24,    9,  295,   49,  375,   15,  558,   56,   34,\n",
              "         344,   16,  181,  195,   31,   16,  115,    0])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Wu6jYu-wwKqM",
        "outputId": "8bd88b65-374b-4c04-9f04-5d1d835ce3df"
      },
      "source": [
        "# Esto es lo que dice, si lo volvemos a codificar en palabras\n",
        "' '.join(num.vocab[o] for o in x[0][:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'xxbos xxmaj quite simply , one of the xxunk xxunk ever written and xxunk it has performances to match .'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "A4e04qU-wKgB",
        "outputId": "1144c29b-da44-4376-c161-5a6ff63bbd40"
      },
      "source": [
        "# Haciendo lo mismo para el target (y), podemos ver que la unica diferencia es \n",
        "# que esta incluye la ultima palabra que faltaria predecir de la frase\n",
        "' '.join(num.vocab[o] for o in y[0][:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'xxmaj quite simply , one of the xxunk xxunk ever written and xxunk it has performances to match . xxmaj'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDQ9wO5Ayda_"
      },
      "source": [
        "## **Training a Text Classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJY0IS1jyl3f"
      },
      "source": [
        "### **Language Model Using DataBlock**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqvvwD-ewKVI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "9ca2e84d-b7aa-4b89-9319-e1335f0bd14f"
      },
      "source": [
        "# Aqui, cargo los textos\n",
        "get_imdb = partial(get_text_files, folders=['train', 'test', 'unsup'])\n",
        "\n",
        "# Ojo que al ejecutar el entrenamiento me salio el mensaje de 'out of memory'\n",
        "# Asi que realice los siguientes cambios\n",
        "# tuve que bajar el bs (128 -> 16)\n",
        "# y el seq_len (80 -> 40)\n",
        "dls_lm = DataBlock(\n",
        "    blocks=TextBlock.from_folder(path, is_lm=True),\n",
        "    get_items=get_imdb, splitter=RandomSplitter(0.1)\n",
        ").dataloaders(path, path=path, bs=16, seq_len=40) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "n9ppaMdPw8i5",
        "outputId": "587d7bd7-3f86-4769-fde6-922f7ded17ef"
      },
      "source": [
        "# Al igual que el resto de los dataloaders, podemos ver un batch \n",
        "# con el metodo show_batch\n",
        "dls_lm.show_batch(max_n=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos i xxmaj like the horror genre and xxup the xxup girl xxup next xxup door is on a different level . \\n\\n xxmaj this movie is so realistic to the teeth , that it makes you think about life</td>\n",
              "      <td>i xxmaj like the horror genre and xxup the xxup girl xxup next xxup door is on a different level . \\n\\n xxmaj this movie is so realistic to the teeth , that it makes you think about life .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>never have been acceptable to any audience . xxmaj now that does n't mean all viewers will appreciate this film . xxmaj no this little hummer is not for the weak at heart or the homophobic . xxmaj in the</td>\n",
              "      <td>have been acceptable to any audience . xxmaj now that does n't mean all viewers will appreciate this film . xxmaj no this little hummer is not for the weak at heart or the homophobic . xxmaj in the end</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcIQuIVjyq0R"
      },
      "source": [
        "### **Fine-Tuning the Language Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AEzWVCvw8XP"
      },
      "source": [
        "# Aqui comenzamos el entranamiento\n",
        "# Esto que estamos ajustando es similar a un modelo de clasificacion, ya que la\n",
        "# palabra que vamos a predecir se debe encontrar en el diccionario que generamos\n",
        "# antes \n",
        "\n",
        "\n",
        "## Notemos que la estructura de red neuronal que vamos a ocupar es AWD_LSTM\n",
        "## Esta posee una primera capa de embedding y otras dos capas densas\n",
        "## Tambien es importante mencionar que utiliza otro optimizador (Adam)\n",
        "learn = language_model_learner(\n",
        "    dls_lm, AWD_LSTM, drop_mult=0.3, \n",
        "    metrics=[accuracy, Perplexity()]).to_fp16()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "IzYcLUFGw8NX",
        "outputId": "ce87cf1f-38e0-48d4-dd57-7277e6e529b3"
      },
      "source": [
        "# Notar que a pesar de haber reducido el batch size y haber aplicado el metodo\n",
        "# to_fp16() el tiempo de entrenamiento fue bastante extenso\n",
        "\n",
        "# Recordar que con el metodo de fit_one_cycle, cambiamos la capa de salida (en \n",
        "# este con nuestro diccionario) y congelamos todos los parametros salvo los \n",
        "# de la ultima capa (solo se modifican los parametros de la capa de salida)\n",
        "learn.fit_one_cycle(1, 2e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>8.240455</td>\n",
              "      <td>7.952467</td>\n",
              "      <td>0.058182</td>\n",
              "      <td>2842.578857</td>\n",
              "      <td>2:58:23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMgYdu74yubV"
      },
      "source": [
        "### **Saving and Loading Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9kd3ZC9w8Ca",
        "outputId": "b49df40c-1c5a-42b9-fb59-126e3645547d"
      },
      "source": [
        "# Dado que me tomo tanto tiempo hacer solo una pasada esta la voy a guardar y \n",
        "# utilizar mas tarde (este archivo peso mas 300 mb, con lo cual seria bueno tenerlo\n",
        "# en el drive si se quiere ocupar despues)\n",
        "learn.save('1epoch')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Path('/root/.fastai/data/imdb/models/1epoch.pth')"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfU8v10diS4j",
        "outputId": "2296d7a9-c542-44d2-f8aa-bf1d0967bc75"
      },
      "source": [
        "learn.save('/content/1epoch')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Path('/content/1epoch.pth')"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us6BHS-tw745"
      },
      "source": [
        "# Volvemos a cargar el modelo guardado\n",
        "learn = learn.load('1epoch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "mTH30tTiw7vX",
        "outputId": "89c9e61a-abba-4eff-ab08-105595228a88"
      },
      "source": [
        "# Aqui podriamos continuar ajustando el modelo, pero en mi caso me tomo cerca de 3 \n",
        "# horas hacer una pasada, asi que por el momento esto lo dejare pendiente \n",
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(10, 2e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/10 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='73' class='' max='42062' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.17% [73/42062 00:20<3:19:43 7.0022]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-a21773809809>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/callback/schedule.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    111\u001b[0m     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n\u001b[1;32m    112\u001b[0m               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParamScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'step'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelStepException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mordered_cbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'order'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, f, gen, *args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_ex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0margfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastcore/basics.py\u001b[0m in \u001b[0;36mmap_ex\u001b[0;34m(iterable, f, gen, *args, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastcore/basics.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_Arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0mfargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Arg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpargs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'missing {event_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'order'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_bn_bias_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mnorm_bias_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/callback/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m     43\u001b[0m                (self.run_valid and not getattr(self, 'training', False)))\n\u001b[1;32m     44\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'after_fit'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;31m#Reset self.run to True at each end of fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/callback/fp16.py\u001b[0m in \u001b[0;36mbefore_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbefore_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskipped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskipped\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mCancelStepException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscales\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txsq0bbuw7kG"
      },
      "source": [
        "# Por ultimo, vamos a guardar todo el modelo salvo la ultima capa (recordardo que\n",
        "# esta transformaria la salida en tipos de probabilidad por la softmax)\n",
        "## El modelo sin la ultima capa, pasa a llamarse 'encoder'\n",
        "learn.save_encoder('finetuned')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTKj6MltyzLo"
      },
      "source": [
        "### **Text Generation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mWtFQETNw7Xu",
        "outputId": "522a27ff-977b-4390-897c-5dd2a8cf026a"
      },
      "source": [
        "# Antes de continuar, miremos como el modelo anterior logra hacer predicciones\n",
        "# para cantinuar la siguiente oracion\n",
        "TEXT = \"I liked this movie because\"\n",
        "N_WORDS = 40\n",
        "N_SENTENCES = 2\n",
        "preds = [learn.predict(TEXT, N_WORDS, temperature=0.75) \n",
        "         for _ in range(N_SENTENCES)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZvMEU5Rw7Mv",
        "outputId": "4a520564-b7a0-48d8-c68f-8851aa1af08e"
      },
      "source": [
        "print(\"\\n\".join(preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i liked this movie because , and how The better is , and as was the film is , as from Starkey in the brilliant And Lowdown ( what is , the Coz is at the new the more the\n",
            "i liked this movie because of this just . a , , drinking that Bars really i , the game it , with The likely and farmhouse was was of a of over , after One football 's 's -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmcR3Eupy30j"
      },
      "source": [
        "### **Creating the Classifier DataLoaders**\n",
        "\n",
        "Lo que sigue ahora es utilizar el modelo de lenguaje preentrenado con los datos de las reseñas y adaptarlo a uno de clasificacion de sentimientos (en este caso, positivo y negativo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xA5s6yqw7DJ"
      },
      "source": [
        "# Asi es como nosotros, en alguna clase anterior, cargamos el modelo de las reseñas\n",
        "## Ojo que ya no estamos utilizando los datos no etiquetados (unsupervised)\n",
        "## Tambien notar que en 'TextBlock.from_folder' estamos utilizando el diccionario\n",
        "## nuevo (is_lm=False porque no vamos a trabajar con un lenguage model)\n",
        "dls_clas = DataBlock(\n",
        "    blocks=(TextBlock.from_folder(path, vocab=dls_lm.vocab, is_lm=False),CategoryBlock),\n",
        "    get_y = parent_label,\n",
        "    get_items=partial(get_text_files, folders=['train', 'test']),\n",
        "    splitter=GrandparentSplitter(valid_name='test')\n",
        ").dataloaders(path, path=path, bs=128, seq_len=72)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "fHLVkncxw64x",
        "outputId": "a1bbb600-6aa9-4ba6-f8d5-545825bd2a0a"
      },
      "source": [
        "# Miremos como vienen armadas estas muestras (input, target)\n",
        "dls_clas.show_batch(max_n=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxmaj match 1 : xxmaj tag xxmaj team xxmaj table xxmaj match xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley vs xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley started things off with a xxmaj tag xxmaj team xxmaj table xxmaj match against xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit . xxmaj according to the rules of the match , both opponents have to go through tables in order to get the win . xxmaj benoit and xxmaj guerrero heated up early on by taking turns hammering first xxmaj spike and then xxmaj bubba xxmaj ray . a xxmaj german xxunk by xxmaj benoit to xxmaj bubba took the wind out of the xxmaj dudley brother . xxmaj spike tried to help his brother , but the referee restrained him while xxmaj benoit and xxmaj guerrero</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xxbos * * attention xxmaj spoilers * * \\n\\n xxmaj first of all , let me say that xxmaj rob xxmaj roy is one of the best films of the 90 's . xxmaj it was an amazing achievement for all those involved , especially the acting of xxmaj liam xxmaj neeson , xxmaj jessica xxmaj lange , xxmaj john xxmaj hurt , xxmaj brian xxmaj cox , and xxmaj tim xxmaj roth . xxmaj michael xxmaj canton xxmaj jones painted a wonderful portrait of the honor and dishonor that men can represent in themselves . xxmaj but alas … \\n\\n it constantly , and unfairly gets compared to \" braveheart \" . xxmaj these are two entirely different films , probably only similar in the fact that they are both about xxmaj scots in historical xxmaj scotland . xxmaj yet , this comparison frequently bothers me because it seems</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xxbos xxmaj by now you 've probably heard a bit about the new xxmaj disney dub of xxmaj miyazaki 's classic film , xxmaj laputa : xxmaj castle xxmaj in xxmaj the xxmaj sky . xxmaj during late summer of 1998 , xxmaj disney released \" kiki 's xxmaj delivery xxmaj service \" on video which included a preview of the xxmaj laputa dub saying it was due out in \" 1 xxrep 3 9 \" . xxmaj it 's obviously way past that year now , but the dub has been finally completed . xxmaj and it 's not \" laputa : xxmaj castle xxmaj in xxmaj the xxmaj sky \" , just \" castle xxmaj in xxmaj the xxmaj sky \" for the dub , since xxmaj laputa is not such a nice word in xxmaj spanish ( even though they use the word xxmaj laputa many times</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3FFbLxmw6Y7"
      },
      "source": [
        "# Otra cosa que es importante de mencionar, es que la longitud de los textos varian\n",
        "# y en este caso, no podemos sumar todos los textos y luego seccionarlos.\n",
        "# Lo que se hace es rellenar los textos con menos palabras y aparte los mini-batch\n",
        "# los intenta generar de manera es estos tengan textos de tamaño similar\n",
        "\n",
        "## Ahora volvemos a generar un modelo AWD_LSTM nuevo\n",
        "learn = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.5, \n",
        "                                metrics=accuracy).to_fp16()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIHCQKqzw6Mz"
      },
      "source": [
        "# Sin embargo, le vamos a cargar esto (para ajustar casi todos los pametros)\n",
        "learn = learn.load_encoder('finetuned')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HZoJf3qy8-1"
      },
      "source": [
        "### **Fine-Tuning the Classifier**\n",
        "\n",
        "Para los problemas de clasificacion de imagenes, lo que se hacia era congelar las primeras capas, entrenar la ultima, luego descongelar todo y entrenar normalmente.\n",
        "\n",
        "En este caso, se han hayado mejores resultados trabajando de la manera que sigue."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "2Lwm9TBEw57g",
        "outputId": "7ec54944-7d72-454d-d226-ce63a55ac9cf"
      },
      "source": [
        "# Trabajamos la ultima capa\n",
        "learn.fit_one_cycle(1, 2e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.682537</td>\n",
              "      <td>0.672927</td>\n",
              "      <td>0.585200</td>\n",
              "      <td>08:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "bpiCdIIAwKEi",
        "outputId": "ea8a205d-267d-4a63-ebbf-cb2e4fabbeeb"
      },
      "source": [
        "# Luego trabajamos las ultimas dos capas, con intervalos de LR\n",
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.645628</td>\n",
              "      <td>0.638529</td>\n",
              "      <td>0.638760</td>\n",
              "      <td>09:18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "ZUHMzvfPwJdO",
        "outputId": "344bf9d2-415f-4a59-b755-09a78b35b2f2"
      },
      "source": [
        "# Luego trabajamos las ultimas 3 capas, tambien con intervalos de LR\n",
        "learn.freeze_to(-3)\n",
        "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.612152</td>\n",
              "      <td>0.576697</td>\n",
              "      <td>0.705600</td>\n",
              "      <td>13:53</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        },
        "id": "gud14fKSxkqN",
        "outputId": "549880da-f9bd-4701-ae95-c30194b3d6a7"
      },
      "source": [
        "# Por ultimo, descongelamos todo y hacemos el entrenamiento de todas las capas\n",
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/2 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/195 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    }
  ]
}